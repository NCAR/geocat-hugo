name: SCRAPE_DOWNLOAD_METRICS_DAILY
on:
  schedule:
     - cron: '0 0 * * *' # Daily “At 00:00”

jobs: 
  metrics:
    name: py
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}

    steps:
      - name: Cancel previous runs
        uses: styfle/cancel-workflow-action@0.8.0
        with:
          access_token: ${{ github.token }}
      - name: checkout repo content
        uses: actions/checkout@v2 # checkout the repository content to github runner.
      - name: conda_setup
        uses: conda-incubator/setup-miniconda@v2
        with:
          activate-environment: vast_conda_metrics
          channel-priority: strict
          mamba-version: '*'
          python-version: 3.8
          channels: conda-forge
      - shell: bash
        run: conda install anaconda-client
      - name: execute py script # run the run.py to get the latest data
        shell: python
        run: |
          import argparse
          from anaconda_client.binstar_client.utils import get_server_api
          from anaconda_clientbinstar_client import errors 

          import os
          import sqlite3
          import yaml

          # detect script dir
          abspath = os.path.abspath(__file__)
          dname = os.path.dirname(abspath)
          os.chdir(dname)

          # determine db_file
          parser = argparse.ArgumentParser(description='Generate conda metrics.')
          parser.add_argument('-d', '--database-file', dest='db_file',
                              help='conda_metrics database file',
                              default=os.path.join(dname, 'conda_metrics.db'))
          parser.add_argument('packages', nargs='*', help='Optional package list')
          args = parser.parse_args()

          # set up sqlite
          conn = sqlite3.connect(args.db_file)
          c = conn.cursor()

          packages_file = 'data/packages.yml'
          with open(packages_file) as f:
            packages_dict = yaml.load(f, Loader=yaml.CLoader)
          packages = [i['package'] for i in packages_dict['items']]
          conda_channels = ['conda-forge', 'ncar']

          if args.packages:
              packages = args.packages

          download_list = []
          for package in packages:
              package_total_dls = 0
              for conda_channel in conda_channels:
                  db_table = package.replace('-', '')

                  aserver_api = get_server_api(log_level=0)
                  try: package_obj = aserver_api.package(conda_channel, package)
                  except errors.NotFound: continue

                  for version_str in package_obj['versions']:
                      version = aserver_api.release(conda_channel, package, version_str)
                      for d in version['distributions']:
                          distribution_downloads = d['ndownloads']\

                          download_list.append(distribution_downloads)

          downloads = sum(download_list)

          metrics_file = 'data/metrics.yml'
          with open(metrics_file, 'r+') as f:
            metrics_dict = yaml.load(f, Loader=yaml.CLoader)
          metrics_dict['counter_item'][0]["number"] = downloads
          with open(metrics_file, 'w') as f:
            yaml.dump(metrics_dict, f)
#        env:
#          key: ${{ secrets.VAST_METRICS }} # if run.py requires passwords..etc, set it as secrets
      - name: git_config
        run: |
          git config --global user.name 'GitHub Actions'
          git config --global user.email 'noreply@github.com'
      - name: push_conda_metrics_db
        run: |
          git commit --allow-empty -am "push_conda_metrics_db"
          git push
